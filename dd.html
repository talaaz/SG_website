<!DOCTYPE html>
<html>

<head>
  <title>Social Graphs</title>
  <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
  <button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>

  <div class="header1">
    <div class="topnav" id="myTopnav">
      <a href="index.html">Home</a>
      <a href="dd.html">Download Data</a>
      <a href="stat.html">Data Stats</a>
      <a href="analysis.html">Data Analysis</a>
      <a href="notebook.html">NoteBook</a>

    </div>
    <div class="title1">
      <h2 class="heading"> Social graphs and networks - stackoverflow</h2>
    </div>
  </div>


  <!-- Download data Section -->
  <section id="dd">
    <div class="container">
      <div class="row">
        <h1>Download Data</h1>
        <div class="block"></div>
        <p>
        <h3>Dataset colleciton</h3><br>
        <p>
          We want to analyze the Stack OverFlow website, to do so we extract the raw data from the bigquery-public-data
          project using Google <a
            href="https://console.cloud.google.com/bigquery?pli=1&project=trim-bot-243812&folder=&organizationId=">BigQuery</a>
          .
          The query resulsts are then narrowed by only querying for data fulfilling the following conditions:
          <br>
          <br>
        <ul>
          -Users having been active within 2020 together with a reputation above 10000, a public location and a "about me" section
          <br>
          - Questions posted on StackOverflow after 01-01-2018 and related to the following programming <br>
          - languages "python, c++, c#, sql, java, javascript, php, .net"
          <br>
          -Answers related to the queried user id's<br>
        </ul>
        </p>

        <h4>Processing the raw data</h4>
        <p><br>
          When extracting the data described above, we end up having: <br><br>
          - Approx. 15.000 users<br>
          - Approx. 1 million questions<br>
          - Approx. 2 million answers<br>

          A total of more than 2GB raw data.<br><br>
          Here is a table over the first five users: <br>
        <div style="overflow-x:auto;">
          <table>
            <tr>
              <th></th>

              <th>id</th>
              <th>reputation</th>
              <th>display_name</th>
              <th>creation_date</th>
              <th>location</th>
              <th>last_access_date</th>
              <th>about_me</th>
              <th>views</th>
              <th>up_votes</th>
              <th>down_votes</th>
            </tr>
            <tr>
              <td>0</td>
              <td>22656</td>
              <td>1206038</td>
              <td>Jon Skeet</td>
              <td>2008-09-26 12:05:05.150000+00:00</td>
              <td>Reading, United Kingdom</td>
              <td>2020-09-05 17:32:07.613000+00:00</td>
              <td>&lt;p&gt;\nAuthor of href="https://www.manning.co..."</td>
              <td>1972774</td>
              <td>16633</td>
              <td>7090</td>
            </tr>
            <tr>
              <td>1</td>
              <td>1144035</td>
              <td>1006490</td>
              <td>Gordon Linoff</td>
              <td>2012-01-11 19:53:57.590000+00:00</td>
              <td>New York, United States</td>
              <td>2020-09-06 02:21:13.123000+00:00</td>
              <td>&lt;p&gt;check out my book href="http</td>
              <td>336960</td>
              <td>17283</td>
              <td>42</td>
            </tr>
            <tr>
              <td>2</td>
              <td>6309</td>
              <td>979770 </td>
              <td>VonC</td>
              <td>2008-09-13 22:22:33.173000+00:00 </td>
              <td>France</td>
              <td>2020-09-06 05:10:37.823000+00:00</td>
              <td>&lt;p&gt;&lt;img src="http://i.stack.imgur.co.</td>
              <td>185652</td>
              <td>56359</td>
              <td>295</td>
            </tr>


            <tr>
              <td>3</td>
              <td>157882</td>
              <td>949855 </td>
              <td>BalusC</td>
              <td>2009-08-17 16:42:02.403000+00:00 </td>
              <td>Willemstad, Cura√ßao</td>
              <td>2020-09-05 23:05:35.913000+00:00</td>
              <td>&lt;p&gt;A href="https://balusc.zeef.com" rel="no..</td>
              <td>438873</td>
              <td>15531</td>
              <td>22108</td>
            </tr>

            <tr>
              <td>4</td>
              <td>29407</td>
              <td>927319 </td>
              <td>Darin Dimitrov </td>
              <td>2008-10-19 16:07:47.823000+00:00</td>
              <td>Sofia, Bulgaria</td>
              <td>2020-09-03 10:50:38.807000+00:00</td>
              <td>&lt;p&gt;I love writing code and I am really passion</td>
              <td>269811</td>
              <td>1955</td>
              <td>2651</td>
            </tr>


          </table>
        </div><br>
        The data was then cleaned by extracting the largest component of
        the network. Then by removing all isolated user , we end up having:<br><br>
        - Approx. 4000 users<br>
        - Approx. 7000 questions<br>
        - Approx. 9000 questions<br>
        </p>

        <h4>Text processing the data</h4>
        <p>
          In order to make our dataset easier to work with,
          we process our data and clean the text data:<br>
          - Removing html tags and uris. <br>
          - Removing punctuation. <br>
          - Removing stopwords.<br>
          - Filtering the question tags to only include one of the main programming languages <br>
        </p>
        <p>Further details can be found in the    <a href="notebook.html">NoteBook</a>. </p>
      </div>




    </div>
  </section>


</body>
<script src="main.js"></script>

</html>